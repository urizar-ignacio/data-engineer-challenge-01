{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío Data Engineer\n",
    "### Ignacio Urízar\n",
    "### Agosto, 2024\n",
    "- [Introducción](#intro)\n",
    "  - [Supuestos](#supuestos)\n",
    "- [Pregunta 1 (Q1)](#q1_pregunta)\n",
    "  - [Benchmark (pandas)](#q1_benchmark)\n",
    "  - [q1_memory](#q1_memory)\n",
    "  - [q1_time](#q1_time)\n",
    "  - [Resultados Q1](#q1_resultados)\n",
    "- [Pregunta 2 (Q2)](#q2_pregunta)\n",
    "  - [q2_memory](#q2_memory)\n",
    "  - [q2_time](#q2_time)\n",
    "  - [Resultados Q2](#q2_resultados)\n",
    "- [Pregunta 3 (Q3)](#q3_pregunta)\n",
    "  - [q3_memory](#q3_memory)\n",
    "  - [q3_time](#q3_time)\n",
    "  - [Resultados Q3](#q3_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "<a id='intro'></a>\n",
    "En este jupyter notebook se presenta el desarrollo del desafío de Data Engineer. El documento se encuentra separado en secciones según se indica en el índice más arriba.\n",
    "\n",
    "Se presenta una sección inicial de [Supuestos](#supuestos) que tomaron en consideración para el desarrollo de las soluciones.\n",
    "\n",
    "Cada sección incluye una descripción del código utilizado para cada solución, las diferencias entre las distintas estrategias de optimización y sus correspondientes perfiles de uso de memoria y tiempo de ejecución.\n",
    "\n",
    "El código fuente se encuentra en el siguiente repositorio público de GitHub: [repositorio](https://github.com/urizar-ignacio/data-engineer-challenge-01).\n",
    "\n",
    "En el README de dicho repositorio se detallan distintas alternativas de ejecución de este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos\n",
    "<a id='supuestos'></a>\n",
    "\n",
    "#### Ubicación del archivo con datos\n",
    "Dado que el archivo con la muestra de datos que se recibió para este desafío supera el límite de tamaño aceptado por GitHub, es necesario depositarlo manualmente en la carpeta `/app/data/` para que las funciones lo puedan leer sin problemas.\n",
    "\n",
    "#### Ambiente de ejecución\n",
    "Este proyecto está desarrollado para ser ejecutado de forma local, ya sea en un computador personal o en una máquina virtual. Se recomienda usar la ejecución con Docker descrita en el README del repositorio para tener ambientes idénticos. Si se opta por una ejecución no contenerizada, se debe contar con una versión de Python compatible con las librerías listadas en el archivo `/app/requirements.txt`.\n",
    "\n",
    "#### Estructura de carpetas\n",
    "Se espera que la estructura de carpetas y distribución de archivos no sea modificada (salvo por la necesidad de incluir manualmente el archivo con la muestra de datos, como se mencionó anteriormente). Para que las importaciones funcionen correctamente se debe mantener la distribución de archivos tal como se presenta en el repositorio:\n",
    "\n",
    "```\n",
    "app/\n",
    "  data/\n",
    "    <archivo_con_data>.json\n",
    "  src/\n",
    "    challenge.ipynb\n",
    "    q1_memory.py\n",
    "    q1_time.py\n",
    "    q2_memory.py\n",
    "    q2_time.py\n",
    "    q3_memory.py\n",
    "    q3_time.py\n",
    "  requirements.txt\n",
    "```\n",
    "\n",
    "#### Flujo de ejecución\n",
    "Todas las soluciones propuestas tendrán el mismo flujo de ejecución:\n",
    "- Explicación de la implementación.\n",
    "- Ejecución directa, para ver el resultado generado.\n",
    "- Perfilado de tiempo de ejecución.\n",
    "- Perfilado de uso de memoria.\n",
    "\n",
    "#### Perfiladores utilizados\n",
    "- Para el perfilado de tiempo de ejecución se utiliza la librería `cProfile`.\n",
    "- Para el perfilado de uso de memoria se utiliza la librería `memory_profiler` y el magic command `%mprun`.\n",
    "\n",
    "#### Reinicio del kernel\n",
    "Notar que entre las ejecuciones de cada solución propuesta se reinició el kernel de ejecución. Esto para asegurar que el perfilado de uso de memoria no se vea afectado a calcular memoria utilizada al momento de definición del método por librerías importadas en otras soluciones. Si bien la parte importante son los aumentos de memoria dentro de cada método, esta distinción se vuelve importante si se quiere analizar el comportamiento completo e independiente de cada solución.\n",
    "\n",
    "#### ¿Qué es un emoji?\n",
    "En la solución de la pregunta 2 (Q2) se pide un conteo de \"emojis\". Para esto es necesario determinar qué se considera un emoji en el alcance de este proyecto. En el contenido del texto de los tweets disponibles en la data de muestra, hay campos en formato `unicode`, algunos representan emojis otros representan caracteres de otras lenguas. Para determinar cuáles de estos caracteres especiales son emojis se utilizó el diccionario disponible en la librería de python `emoji (version 2.12.1)`. Por lo que si un emoji no está incluído en ese diccionario, no aparecerá contabilizado como tal.\n",
    "\n",
    "#### Usernames en X (ex-Twitter)\n",
    "La creación de usernames tiene algunas restricciones básicas que se deben considerar según aparece documentado en [help.x.com](https://help.x.com/en/managing-your-account/x-username-rules). Un username debe tener entre 4 y 15 caracteres, solo alfanuméricos y guión bajo. Esto se tendrá en consideración al momento de buscar menciones en la pregunta 3 (Q3), asegurando así que no se consideren para el conteo menciones como `@a`, `@123`, `@ho.la`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1 (Q1)\n",
    "<a id='q1_pregunta'></a>\n",
    "\n",
    "Se requiere obtener los 10 días con más tweets. De estos 10 días se necesita identificar al usuario que realizó más posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark (pandas)\n",
    "<a id='q1_benchmark'></a>\n",
    "\n",
    "Antes de comenzar con los procesos de optimización, se decidió resolver la pregunta 1 usando herramientas recurrentes en flujos de data engineering y analytics. Para este caso se utilizó `pandas`, con la idea de tener un punto de comparación base sobre el cual buscar rutas de optimización de tiempo y recursos.\n",
    "\n",
    "Para esto se incluyó un archivo adicional: `app/src/q1_benchmark.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_benchmark import q1_benchmark\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q1_benchmark(file_path: str)**\n",
    "\n",
    "Toma la ruta del archivo de datos como parámetro. Abre el archivo y lo lee línea por línea y deserializa cada registro como un diccionario y los almacena en una lista. Esa lista de diccionarios es usada para crear un `DataFrame` de `pandas`. Se procesan la columna `\"date\"` para eliminar la parte que contiene la hora y obtiene el campo `\"username\"` desde el diccionario anidado `\"user\"`.\n",
    "\n",
    "Con el `DataFrame` procesado, se agrupa por `\"date\"` para obtener el top 10 de días con más tweets y luego se agrupa por `\"date\"`y `\"username\"` para obtener los usuarios con más tweets por cada día.\n",
    "\n",
    "Estos resultados se cruzan para obtener el usuario con más tweets por cada días del top de días con más tweets \"over-all\".\n",
    "\n",
    "El `DataFrame` resultante se transforma en una lista de tuplas y es retornado como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q1_benchmark(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[datetime.date, str]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1871333 function calls (1871106 primitive calls) in 6.685 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       78    0.000    0.000    0.000    0.000 <frozen abc>:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.052    0.000    0.113    0.000 <frozen codecs>:319(decode)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "        1    0.066    0.066    6.685    6.685 <string>:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 __init__.py:225(compile)\n",
      "        4    0.000    0.000    0.000    0.000 __init__.py:272(_compile)\n",
      "   117407    0.110    0.000    4.926    0.000 __init__.py:299(loads)\n",
      "       49    0.000    0.000    0.000    0.000 __init__.py:34(using_copy_on_write)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:42(warn_copy_on_write)\n",
      "       42    0.000    0.000    0.000    0.000 __init__.py:55(using_pyarrow_string_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 _asarray.py:108(<setcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 _asarray.py:27(require)\n",
      "        1    0.000    0.000    0.000    0.000 _decorators.py:325(wrapper)\n",
      "       20    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
      "       20    0.000    0.000    0.000    0.000 _dtype.py:336(_name_includes_bit_suffix)\n",
      "       20    0.000    0.000    0.000    0.000 _dtype.py:352(_name_get)\n",
      "        1    0.000    0.000    0.000    0.000 _function_base_impl.py:343(iterable)\n",
      "        1    0.000    0.000    0.000    0.000 _function_base_impl.py:5392(_delete_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 _function_base_impl.py:5396(delete)\n",
      "        4    0.000    0.000    0.000    0.000 _function_base_impl.py:5575(_insert_dispatcher)\n",
      "        4    0.000    0.000    0.000    0.000 _function_base_impl.py:5579(insert)\n",
      "        8    0.000    0.000    0.000    0.000 _function_base_impl.py:5762(_append_dispatcher)\n",
      "        8    0.000    0.000    0.000    0.000 _function_base_impl.py:5766(append)\n",
      "        6    0.000    0.000    0.000    0.000 _methods.py:42(_amax)\n",
      "        3    0.000    0.000    0.000    0.000 _methods.py:46(_amin)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:50(_sum)\n",
      "       16    0.000    0.000    0.000    0.000 _methods.py:58(_any)\n",
      "        2    0.000    0.000    0.000    0.000 _methods.py:67(_all)\n",
      "       10    0.000    0.000    0.000    0.000 _strptime.py:26(_getlang)\n",
      "       10    0.000    0.000    0.000    0.000 _strptime.py:309(_strptime)\n",
      "       10    0.000    0.000    0.000    0.000 _strptime.py:565(_strptime_datetime)\n",
      "       15    0.000    0.000    0.000    0.000 _validators.py:226(validate_bool_kwarg)\n",
      "        1    0.000    0.000    0.000    0.000 _validators.py:354(validate_ascending)\n",
      "        1    0.000    0.000    0.006    0.006 accessor.py:188(__init__)\n",
      "        1    0.006    0.006    0.006    0.006 accessor.py:207(_validate)\n",
      "        1    0.000    0.000    0.006    0.006 accessor.py:220(__get__)\n",
      "        1    0.000    0.000    0.048    0.048 accessor.py:248(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 accessor.py:255(_wrap_result)\n",
      "        4    0.000    0.000    0.000    0.000 algorithms.py:106(_ensure_data)\n",
      "        6    0.000    0.000    0.001    0.000 algorithms.py:1131(take)\n",
      "        3    0.001    0.000    0.020    0.007 algorithms.py:1452(safe_sort)\n",
      "        1    0.032    0.032    0.049    0.049 algorithms.py:1667(map_array)\n",
      "        6    0.000    0.000    0.000    0.000 algorithms.py:184(_reconstruct_data)\n",
      "        3    0.000    0.000    0.000    0.000 algorithms.py:217(_ensure_arraylike)\n",
      "        3    0.000    0.000    0.010    0.003 algorithms.py:262(_get_hashtable_algo)\n",
      "        3    0.010    0.003    0.010    0.003 algorithms.py:280(_check_object_for_strings)\n",
      "        3    0.037    0.012    0.048    0.016 algorithms.py:548(factorize_array)\n",
      "        3    0.000    0.000    0.068    0.023 algorithms.py:610(factorize)\n",
      "        1    0.001    0.001    0.001    0.001 algorithms.py:994(duplicated)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:102(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:106(_get_distinct_objs)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:120(_get_combined_index)\n",
      "        4    0.000    0.000    0.000    0.000 api.py:386(default_index)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:72(get_objs_combined_axis)\n",
      "        1    0.000    0.000    0.000    0.000 apply.py:121(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 apply.py:1377(__init__)\n",
      "        1    0.000    0.000    0.049    0.049 apply.py:1409(apply)\n",
      "        1    0.000    0.000    0.049    0.049 apply.py:1482(apply_standard)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:1010(view)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:1146(take)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:1176(_maybe_disallow_fill)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:122(_reset_cache)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1250(copy)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:1364(_duplicated)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:159(_freeze)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:166(__setattr__)\n",
      "       40    0.000    0.000    0.000    0.000 base.py:1671(name)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1697(_validate_names)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1730(_get_default_index_names)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:1765(_get_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1768(_set_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1809(set_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1922(rename)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:1979(nlevels)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1992(_validate_index_level)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:2066(_get_level_values)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:214(_obj_with_exclusions)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:2229(is_monotonic_increasing)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:2313(is_unique)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:232(__getitem__)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:238(construct_from_string)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:2744(inferred_type)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:2776(_is_multi)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:2794(_na_value)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3071(drop_duplicates)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3211(_validate_sort_keyword)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:323(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:332(array)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3439(_wrap_setop_result)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3449(intersection)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:346(shape)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3535(_intersection)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3565(_wrap_intersection_result)\n",
      "       25    0.000    0.000    0.000    0.000 base.py:363(ndim)\n",
      "        1    0.000    0.000    0.004    0.004 base.py:365(grouped_reduce)\n",
      "        1    0.000    0.000    0.047    0.047 base.py:37(_str_getitem)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3760(_assert_can_do_setop)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3766(_convert_can_do_setop)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:3777(get_loc)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:3809(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:3820(get_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:3955(_get_indexer)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:3996(_check_indexing_method)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:400(_inner_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4191(_validate_positional_slice)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:4201(_convert_slice_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4323(reindex)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4436(_wrap_reindex_result)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4440(_maybe_preserve_names)\n",
      "       17    0.000    0.000    0.000    0.000 base.py:456(_engine_type)\n",
      "       18    0.000    0.000    0.003    0.000 base.py:475(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5058(_can_use_libjoin)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5088(values)\n",
      "      140    0.000    0.000    0.000    0.000 base.py:5144(_values)\n",
      "       21    0.000    0.000    0.000    0.000 base.py:5170(_get_engine_target)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5204(_get_join_target)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5224(_from_join_target)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:5295(_validate_fill_value)\n",
      "       31    0.000    0.000    0.000    0.000 base.py:5323(__contains__)\n",
      "       18    0.000    0.000    0.000    0.000 base.py:5373(__getitem__)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:540(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:5425(_getitem_slice)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5437(_can_hold_identifiers_and_holds_name)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5455(append)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5486(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:549(find)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5491(_concat)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5495(<listcomp>)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:5552(equals)\n",
      "       18    0.000    0.000    0.000    0.000 base.py:591(_ensure_array)\n",
      "       18    0.000    0.000    0.000    0.000 base.py:609(_dtype_to_subclass)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:6162(get_indexer_for)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6186(_get_indexer_strict)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6219(_raise_if_missing)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:6312(_index_as_unique)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:6324(_maybe_downcast_for_indexing)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:6394(_should_compare)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:6415(_is_comparable_dtype)\n",
      "       53    0.001    0.000    0.001    0.000 base.py:649(_simple_new)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:6672(_maybe_cast_indexer)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:6679(_maybe_cast_listlike_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:6685(_validate_indexer)\n",
      "        9    0.000    0.000    0.001    0.000 base.py:674(_with_infer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6916(delete)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:692(_constructor)\n",
      "        4    0.000    0.000    0.001    0.000 base.py:6956(insert)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:7031(drop)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:74(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:7553(ensure_index_from_sequences)\n",
      "       36    0.000    0.000    0.001    0.000 base.py:7593(ensure_index)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:7652(ensure_has_len)\n",
      "       24    0.000    0.000    0.000    0.000 base.py:7688(maybe_extract_name)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:7723(_unpack_nested_dtype)\n",
      "       24    0.000    0.000    0.000    0.000 base.py:773(_view)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:782(_rename)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:791(is_)\n",
      "       18    0.000    0.000    0.000    0.000 base.py:82(shape)\n",
      "       61    0.000    0.000    0.000    0.000 base.py:831(_reset_identity)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:836(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:838(_cleanup)\n",
      "       51    0.000    0.000    0.000    0.000 base.py:84(<genexpr>)\n",
      "       17    0.000    0.000    0.000    0.000 base.py:842(_engine)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:86(_validate_set_axis)\n",
      "        1    0.000    0.000    0.049    0.049 base.py:891(_map_values)\n",
      "      106    0.000    0.000    0.000    0.000 base.py:909(__len__)\n",
      "       25    0.000    0.000    0.000    0.000 base.py:974(dtype)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:1249(shape)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:1253(iget)\n",
      "        4    0.000    0.000    0.000    0.000 blocks.py:1262(_slice)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:1287(take_nd)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:1935(delete)\n",
      "       22    0.000    0.000    0.000    0.000 blocks.py:214(is_extension)\n",
      "       11    0.000    0.000    0.000    0.000 blocks.py:219(_can_consolidate)\n",
      "        7    0.000    0.000    0.000    0.000 blocks.py:225(_consolidate_key)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:230(_can_hold_na)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:253(fill_value)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:2582(array_values)\n",
      "       16    0.000    0.000    0.000    0.000 blocks.py:2645(maybe_coerce_values)\n",
      "       14    0.000    0.000    0.000    0.000 blocks.py:266(mgr_locs)\n",
      "       21    0.000    0.000    0.000    0.000 blocks.py:2674(get_block_type)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:2703(new_block_2d)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:2716(new_block)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:274(make_block)\n",
      "       14    0.000    0.000    0.000    0.000 blocks.py:2795(extend_blocks)\n",
      "        7    0.000    0.000    0.000    0.000 blocks.py:2811(ensure_block_shape)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:292(make_block_same_class)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:320(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:324(slice_block_columns)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:350(getitem_block_columns)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:387(apply)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:414(_split_op_result)\n",
      "       23    0.000    0.000    0.000    0.000 blocks.py:718(dtype)\n",
      "       10    0.000    0.000    0.000    0.000 blocks.py:790(copy)\n",
      "       52    0.004    0.000    0.004    0.000 cast.py:1157(maybe_infer_to_datetimelike)\n",
      "        3    0.000    0.000    0.001    0.000 cast.py:124(maybe_convert_platform)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1433(find_common_type)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1580(construct_1d_object_array_from_listlike)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1605(maybe_cast_to_integer_array)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1763(np_can_hold_element)\n",
      "       14    0.000    0.000    0.000    0.000 cast.py:551(maybe_promote)\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:973(coerce_indexer_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:103(_maybe_match_name)\n",
      "       19    0.000    0.000    0.000    0.000 common.py:1040(needs_i8_conversion)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:1081(is_numeric_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1122(<lambda>)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:1198(is_bool_dtype)\n",
      "       19    0.000    0.000    0.000    0.000 common.py:121(classes)\n",
      "       19    0.000    0.000    0.000    0.000 common.py:123(<lambda>)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:126(_classes_and_not_datetimelike)\n",
      "       29    0.000    0.000    0.000    0.000 common.py:1270(is_1d_only_ea_dtype)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:131(<lambda>)\n",
      "       36    0.000    0.000    0.000    0.000 common.py:1331(is_ea_or_datetimelike_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1342(is_complex_dtype)\n",
      "       18    0.000    0.000    0.000    0.000 common.py:137(is_object_dtype)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:1375(_is_dtype)\n",
      "       15    0.000    0.000    0.000    0.000 common.py:1399(_get_dtype)\n",
      "       27    0.000    0.000    0.000    0.000 common.py:1434(_is_dtype_type)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:152(cast_scalar_indexer)\n",
      "       11    0.000    0.000    0.000    0.000 common.py:1571(validate_all_hashable)\n",
      "       23    0.000    0.000    0.000    0.000 common.py:1590(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1596(pandas_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:174(not_none)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:178(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:195(any_not_none)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:199(<genexpr>)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:231(asarray_tuplesafe)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:295(maybe_make_list)\n",
      "       20    0.000    0.000    0.000    0.000 common.py:372(apply_if_callable)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:529(is_string_or_object_np_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:535(temp_setattr)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:536(is_string_dtype)\n",
      "       29    0.000    0.000    0.000    0.000 common.py:568(require_length_match)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:572(condition)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:633(is_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:641(fill_missing_names)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:657(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:81(get_op_result_name)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:86(consensus_name_attr)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:97(is_bool_indexer)\n",
      "        2    0.000    0.000    0.001    0.000 concat.py:157(concat)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:202(_maybe_reindex_columns_na_proxy)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:405(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:480(_get_ndims)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:494(_clean_keys_and_objs)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:52(concat_compat)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:545(_get_sample_object)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:567(<listcomp>)\n",
      "        2    0.000    0.000    0.001    0.000 concat.py:622(get_result)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:635(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:693(_get_result_dim)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:699(new_axes)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:702(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:707(_get_comb_axis)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:717(_get_concat_axis)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:724(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:73(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:751(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:770(_maybe_check_integrity)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:777(_concat_indexes)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:94(concatenate_managers)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:127(_get_single_key)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:145(_get_option)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:617(_select_options)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:635(_get_root)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:649(_get_deprecated_option)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:676(_translate_key)\n",
      "        1    0.000    0.000    0.137    0.137 construction.py:1006(convert_object_array)\n",
      "       21    0.135    0.006    0.137    0.007 construction.py:1028(convert)\n",
      "        1    0.000    0.000    0.137    0.137 construction.py:1070(<listcomp>)\n",
      "       56    0.000    0.000    0.000    0.000 construction.py:416(extract_array)\n",
      "       36    0.000    0.000    0.000    0.000 construction.py:481(ensure_wrapped_if_datetimelike)\n",
      "       47    0.000    0.000    0.004    0.000 construction.py:517(sanitize_array)\n",
      "        1    0.000    0.000    0.002    0.002 construction.py:596(_homogenize)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:638(_extract_index)\n",
      "        3    0.000    0.000    0.000    0.000 construction.py:688(_sanitize_non_ordered)\n",
      "       47    0.000    0.000    0.000    0.000 construction.py:696(_sanitize_ndim)\n",
      "       47    0.000    0.000    0.000    0.000 construction.py:735(_sanitize_str_dtypes)\n",
      "       47    0.000    0.000    0.000    0.000 construction.py:758(_maybe_repeat)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:769(_try_cast)\n",
      "        1    0.002    0.002    0.480    0.480 construction.py:793(to_arrays)\n",
      "        1    0.177    0.177    0.340    0.340 construction.py:891(_list_of_dict_to_arrays)\n",
      "   117408    0.122    0.000    0.131    0.000 construction.py:915(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:916(<genexpr>)\n",
      "        1    0.030    0.030    0.030    0.030 construction.py:922(<listcomp>)\n",
      "        1    0.000    0.000    0.138    0.138 construction.py:928(_finalize_columns_and_data)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:950(_validate_or_indexify_columns)\n",
      "        1    0.019    0.019    0.156    0.156 construction.py:96(arrays_to_mgr)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:104(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:132(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:141(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:287(helper)\n",
      "   117407    0.190    0.000    4.770    0.000 decoder.py:332(decode)\n",
      "   117407    4.440    0.000    4.440    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:1054(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:1305(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:1454(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:1835(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:2228(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:342(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:831(construct_from_string)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:1256(value)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:193(__get__)\n",
      "       34    0.000    0.000    0.000    0.000 flags.py:51(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 flags.py:55(allows_duplicate_labels)\n",
      "       30    0.000    0.000    0.000    0.000 flags.py:87(allows_duplicate_labels)\n",
      "       18    0.000    0.000    0.000    0.000 frame.py:1030(axes)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:1047(shape)\n",
      "        1    0.000    0.000    0.002    0.002 frame.py:10580(join)\n",
      "        2    0.000    0.000    0.002    0.001 frame.py:12675(_reindex_for_setitem)\n",
      "        7    0.000    0.000    0.000    0.000 frame.py:1643(__len__)\n",
      "        1    0.000    0.000    0.636    0.636 frame.py:2318(from_records)\n",
      "        8    0.000    0.000    0.001    0.000 frame.py:3983(_ixs)\n",
      "       16    0.000    0.000    0.002    0.000 frame.py:4062(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:4130(_getitem_bool_array)\n",
      "        2    0.000    0.000    0.004    0.002 frame.py:4271(__setitem__)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:4470(_iset_item_mgr)\n",
      "        2    0.000    0.000    0.001    0.001 frame.py:4481(_set_item_mgr)\n",
      "        2    0.000    0.000    0.004    0.002 frame.py:4514(_set_item)\n",
      "        5    0.000    0.000    0.000    0.000 frame.py:4585(_ensure_valid_index)\n",
      "        8    0.000    0.000    0.000    0.000 frame.py:4608(_box_col_values)\n",
      "       14    0.000    0.000    0.000    0.000 frame.py:4623(_clear_item_cache)\n",
      "       12    0.000    0.000    0.001    0.000 frame.py:4626(_get_item_cache)\n",
      "        3    0.000    0.000    0.002    0.001 frame.py:5095(insert)\n",
      "        5    0.000    0.000    0.003    0.001 frame.py:5242(_sanitize_column)\n",
      "        2    0.000    0.000    0.001    0.000 frame.py:5993(set_index)\n",
      "        2    0.000    0.000    0.004    0.002 frame.py:6239(reset_index)\n",
      "       10    0.000    0.000    0.000    0.000 frame.py:659(_constructor_from_mgr)\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:6731(drop_duplicates)\n",
      "        8    0.000    0.000    0.000    0.000 frame.py:678(_constructor_sliced_from_mgr)\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:6828(duplicated)\n",
      "        2    0.000    0.000    0.001    0.000 frame.py:9041(groupby)\n",
      "        3    0.000    0.000    0.000    0.000 fromnumeric.py:1081(_argsort_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 fromnumeric.py:1085(argsort)\n",
      "        8    0.000    0.000    0.000    0.000 fromnumeric.py:1842(_ravel_dispatcher)\n",
      "        8    0.000    0.000    0.000    0.000 fromnumeric.py:1846(ravel)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1955(_nonzero_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1959(nonzero)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2508(_all_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2513(all)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2776(_max_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2781(max)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:3063(_prod_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:3068(prod)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:89(_wrapreduction_any_all)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:91(<dictcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 frozen.py:76(__getitem__)\n",
      "        3    0.000    0.000    0.000    0.000 function.py:64(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1532(__neg__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1534(blk_func)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:155(_wrap_agged_manager)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:160(_get_data_to_aggregate)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:1740(_is_level_reference)\n",
      "        5    0.000    0.000    0.000    0.000 generic.py:1771(_is_label_reference)\n",
      "       10    0.000    0.000    0.000    0.000 generic.py:1793(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 generic.py:1798(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:1826(_check_label_or_level_ambiguity)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:1847(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1870(_get_label_or_level_values)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1903(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1939(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1953(_gotitem)\n",
      "        7    0.000    0.000    0.000    0.000 generic.py:2077(__contains__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:2082(empty)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:2140(<genexpr>)\n",
      "       34    0.000    0.000    0.000    0.000 generic.py:278(__init__)\n",
      "       28    0.000    0.000    0.000    0.000 generic.py:339(_from_mgr)\n",
      "       30    0.000    0.000    0.000    0.000 generic.py:363(attrs)\n",
      "      348    0.000    0.000    0.000    0.000 generic.py:37(_check)\n",
      "        3    0.000    0.000    0.001    0.000 generic.py:4027(take)\n",
      "       62    0.000    0.000    0.000    0.000 generic.py:405(flags)\n",
      "        3    0.000    0.000    0.001    0.000 generic.py:4142(_take_with_is_copy)\n",
      "      348    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4342(_getitem_slice)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4361(_slice)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:4379(_set_is_copy)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4402(_check_setitem_copy)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4477(__delitem__)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:4518(_check_inplace_and_allows_duplicate_labels)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:4757(drop)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:4796(_drop_axis)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:511(_validate_dtype)\n",
      "       43    0.000    0.000    0.000    0.000 generic.py:572(_get_axis_number)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:580(_get_axis_name)\n",
      "       14    0.000    0.000    0.000    0.000 generic.py:586(_get_axis)\n",
      "        7    0.000    0.000    0.000    0.000 generic.py:592(_get_block_manager_axis)\n",
      "       32    0.000    0.000    0.000    0.000 generic.py:6236(__finalize__)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:6270(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:6277(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:6284(__getattr__)\n",
      "       67    0.000    0.000    0.000    0.000 generic.py:6301(__setattr__)\n",
      "        5    0.000    0.000    0.001    0.000 generic.py:6662(copy)\n",
      "       14    0.000    0.000    0.000    0.000 generic.py:667(_info_axis)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:696(ndim)\n",
      "       16    0.000    0.000    0.000    0.000 generic.py:807(_set_axis)\n",
      "        3    0.000    0.000    0.001    0.000 groupby.py:1296(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 groupby.py:1340(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 groupby.py:1357(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 groupby.py:1567(_maybe_transpose_result)\n",
      "        1    0.000    0.000    0.000    0.000 groupby.py:1578(_wrap_aggregated_output)\n",
      "        1    0.000    0.000    0.000    0.000 groupby.py:2142(_obj_1d_constructor)\n",
      "        1    0.000    0.000    0.011    0.011 groupby.py:2264(count)\n",
      "        1    0.000    0.000    0.004    0.004 groupby.py:2329(hfunc)\n",
      "        1    0.000    0.000    0.068    0.068 groupby.py:2985(size)\n",
      "        3    0.000    0.000    0.000    0.000 groupby.py:5565(_reindex_output)\n",
      "        3    0.000    0.000    0.000    0.000 groupby.py:5607(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:1080(_is_label_like)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:1084(_convert_grouper)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:527(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:638(_passed_categorical)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:643(name)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:661(_ilevel)\n",
      "        4    0.000    0.000    0.000    0.000 grouper.py:676(ngroups)\n",
      "        5    0.000    0.000    0.068    0.014 grouper.py:689(codes)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:722(_result_index)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:744(_group_index)\n",
      "        3    0.000    0.000    0.068    0.023 grouper.py:777(_codes_and_uniques)\n",
      "        2    0.000    0.000    0.000    0.000 grouper.py:846(get_grouper)\n",
      "        5    0.000    0.000    0.000    0.000 grouper.py:947(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 grouper.py:948(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 grouper.py:949(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:983(is_in_axis)\n",
      "        3    0.000    0.000    0.000    0.000 grouper.py:999(is_in_obj)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1165(_check_deprecated_callable_usage)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1176(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:161(iloc)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1696(_get_list_axis)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1719(_getitem_axis)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1756(_get_slice_axis)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2632(check_bool_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2752(need_slice)\n",
      "       18    0.000    0.000    0.000    0.000 indexing.py:2765(check_dict_or_set_indexers)\n",
      "        8    0.000    0.000    0.000    0.000 inference.py:195(is_array_like)\n",
      "        8    0.000    0.000    0.000    0.000 inference.py:273(is_dict_like)\n",
      "       25    0.000    0.000    0.000    0.000 inference.py:300(<genexpr>)\n",
      "       70    0.000    0.000    0.000    0.000 inference.py:334(is_hashable)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:396(normalize)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:479(_parse_localename)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:593(getlocale)\n",
      "        8    0.000    0.000    0.000    0.000 managers.py:1012(iget)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1066(iset)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1128(value_getitem)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1216(_iset_split_block)\n",
      "        4    0.000    0.000    0.001    0.000 managers.py:1347(insert)\n",
      "       16    0.000    0.000    0.000    0.000 managers.py:1392(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:1402(_insert_update_mgr_locs)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:1412(_insert_update_blklocs_and_blknos)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1434(idelete)\n",
      "        7    0.000    0.000    0.000    0.000 managers.py:1764(is_consolidated)\n",
      "        7    0.000    0.000    0.000    0.000 managers.py:1772(_consolidate_check)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1778(<listcomp>)\n",
      "        7    0.000    0.000    0.098    0.014 managers.py:1782(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1796(concat_horizontal)\n",
      "       18    0.000    0.000    0.000    0.000 managers.py:180(blknos)\n",
      "        8    0.000    0.000    0.000    0.000 managers.py:1828(ndim)\n",
      "       21    0.000    0.000    0.000    0.000 managers.py:1837(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:1850(from_blocks)\n",
      "        7    0.000    0.000    0.000    0.000 managers.py:1863(from_array)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1875(to_2d_mgr)\n",
      "       18    0.000    0.000    0.000    0.000 managers.py:1940(_block)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:196(blklocs)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1974(get_slice)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1989(index)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:1993(dtype)\n",
      "       21    0.000    0.000    0.000    0.000 managers.py:2004(internal_values)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2008(array_values)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2017(_can_hold_na)\n",
      "        1    0.000    0.000    0.135    0.135 managers.py:2121(create_block_manager_from_column_arrays)\n",
      "       21    0.000    0.000    0.000    0.000 managers.py:2177(_grouping_func)\n",
      "        1    0.000    0.000    0.037    0.037 managers.py:2190(_form_blocks)\n",
      "        5    0.031    0.006    0.037    0.007 managers.py:2246(_stack_arrays)\n",
      "        2    0.000    0.000    0.098    0.049 managers.py:2259(_consolidate)\n",
      "       14    0.000    0.000    0.000    0.000 managers.py:2264(<lambda>)\n",
      "        3    0.073    0.024    0.097    0.032 managers.py:2276(_merge_blocks)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:2285(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:2294(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:2311(_fast_count_smallints)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:2320(_preprocess_slice_or_indexer)\n",
      "       16    0.000    0.000    0.000    0.000 managers.py:236(set_axis)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:241(is_single_block)\n",
      "       21    0.000    0.000    0.000    0.000 managers.py:246(items)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:291(arrays)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:303(<listcomp>)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:317(apply)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:344(<dictcomp>)\n",
      "        8    0.000    0.000    0.001    0.000 managers.py:557(copy)\n",
      "       13    0.000    0.000    0.000    0.000 managers.py:583(copy_func)\n",
      "        7    0.000    0.000    0.000    0.000 managers.py:586(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:623(reindex_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:687(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:708(_slice_take_blocks_ax0)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:761(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:869(take)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:913(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:935(_verify_integrity)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:937(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:948(from_blocks)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:1002(_maybe_add_join_keys)\n",
      "        2    0.000    0.000    0.000    0.000 merge.py:1012(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:1129(_get_join_info)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:1232(_get_merge_keys)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:1255(<lambda>)\n",
      "        1    0.000    0.000    0.002    0.002 merge.py:135(merge)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:1363(_maybe_coerce_merge_keys)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:1554(_validate_left_right_on)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:2370(_left_join_on_index)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:2398(_factorize_keys)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:2588(_convert_arrays_and_get_rizer_klass)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:2674(_should_fill)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:2680(_any)\n",
      "        4    0.000    0.000    0.000    0.000 merge.py:2684(_validate_operand)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:2697(_items_overlap_with_suffix)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:737(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:815(_maybe_require_matching_dtypes)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:821(_validate_tolerance)\n",
      "        1    0.000    0.000    0.001    0.001 merge.py:825(_reindex_and_concat)\n",
      "        1    0.000    0.000    0.002    0.002 merge.py:882(get_result)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:958(_maybe_restore_index_levels)\n",
      "        7    0.000    0.000    0.014    0.002 missing.py:101(isna)\n",
      "        4    0.000    0.000    0.000    0.000 missing.py:1073(clean_reindex_fill_method)\n",
      "        7    0.000    0.000    0.014    0.002 missing.py:184(_isna)\n",
      "        3    0.000    0.000    0.014    0.005 missing.py:261(_isna_array)\n",
      "        2    0.014    0.007    0.014    0.007 missing.py:305(_isna_string_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 missing.py:466(array_equivalent)\n",
      "        3    0.000    0.000    0.000    0.000 missing.py:564(_array_equivalent_object)\n",
      "        9    0.000    0.000    0.000    0.000 missing.py:673(na_value_for_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 missing.py:728(is_valid_na_for_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 multi.py:1046(nlevels)\n",
      "       20    0.000    0.000    0.000    0.000 multi.py:1081(codes)\n",
      "        3    0.000    0.000    0.000    0.000 multi.py:1085(_set_codes)\n",
      "        9    0.000    0.000    0.000    0.000 multi.py:1102(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 multi.py:1248(copy)\n",
      "        1    0.000    0.000    0.000    0.000 multi.py:1316(view)\n",
      "        7    0.000    0.000    0.000    0.000 multi.py:1571(_get_names)\n",
      "        3    0.000    0.000    0.000    0.000 multi.py:1574(_set_names)\n",
      "        1    0.000    0.000    0.000    0.000 multi.py:2183(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 multi.py:2207(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 multi.py:325(__new__)\n",
      "        6    0.000    0.000    0.000    0.000 multi.py:4120(_coerce_indexer_frozen)\n",
      "       17    0.000    0.000    0.000    0.000 multi.py:830(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 multi.py:844(levels)\n",
      "        2    0.000    0.000    0.000    0.000 multi.py:897(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 multi.py:903(_set_levels)\n",
      "        9    0.000    0.000    0.000    0.000 multi.py:924(<genexpr>)\n",
      "       91    0.000    0.000    0.000    0.000 multiarray.py:1089(copyto)\n",
      "        3    0.000    0.000    0.000    0.000 multiarray.py:1140(putmask)\n",
      "       20    0.000    0.000    0.000    0.000 multiarray.py:161(concatenate)\n",
      "        5    0.000    0.000    0.000    0.000 multiarray.py:901(bincount)\n",
      "        8    0.000    0.000    0.000    0.000 numeric.py:1373(normalize_axis_tuple)\n",
      "        8    0.000    0.000    0.000    0.000 numeric.py:1424(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:143(ones)\n",
      "        4    0.000    0.000    0.000    0.000 numeric.py:1433(_moveaxis_dispatcher)\n",
      "        4    0.000    0.000    0.000    0.000 numeric.py:1437(moveaxis)\n",
      "        4    0.000    0.000    0.000    0.000 numeric.py:1499(<listcomp>)\n",
      "       90    0.001    0.000    0.001    0.000 numeric.py:300(full)\n",
      "        4    0.000    0.000    0.000    0.000 numerictypes.py:288(issubclass_)\n",
      "        2    0.000    0.000    0.000    0.000 numerictypes.py:470(issubdtype)\n",
      "        1    0.000    0.000    0.000    0.000 numpy_.py:153(__array__)\n",
      "        1    0.000    0.000    0.000    0.000 numpy_.py:95(__init__)\n",
      "        1    0.000    0.000    0.047    0.047 object_array.py:304(_str_slice)\n",
      "   117407    0.017    0.000    0.017    0.000 object_array.py:306(<lambda>)\n",
      "        1    0.020    0.020    0.047    0.047 object_array.py:46(_str_map)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:578(__init__)\n",
      "       18    0.000    0.000    0.000    0.000 ops.py:592(groupings)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:596(shape)\n",
      "        6    0.000    0.000    0.000    0.000 ops.py:598(<genexpr>)\n",
      "        2    0.000    0.000    0.062    0.031 ops.py:687(codes)\n",
      "        2    0.000    0.000    0.062    0.031 ops.py:690(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:696(names)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:698(<listcomp>)\n",
      "        1    0.000    0.000    0.068    0.068 ops.py:700(size)\n",
      "        2    0.000    0.000    0.073    0.036 ops.py:743(group_info)\n",
      "        2    0.000    0.000    0.073    0.036 ops.py:758(_get_compressed_codes)\n",
      "        1    0.000    0.000    0.001    0.001 ops.py:776(reconstructed_codes)\n",
      "        2    0.000    0.000    0.001    0.001 ops.py:782(result_index)\n",
      "        1    0.000    0.000    0.000    0.000 ops.py:788(<listcomp>)\n",
      "   117407    0.017    0.000    0.017    0.000 q1_benchmark.py:13(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 q1_benchmark.py:21(<listcomp>)\n",
      "        1    0.694    0.694    6.619    6.619 q1_benchmark.py:6(q1_benchmark)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:1148(take)\n",
      "        5    0.000    0.000    0.000    0.000 range.py:201(_simple_new)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:231(_constructor)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:280(start)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:315(step)\n",
      "        7    0.000    0.000    0.000    0.000 range.py:376(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:483(_view)\n",
      "        7    0.000    0.000    0.000    0.000 range.py:553(equals)\n",
      "       60    0.000    0.000    0.000    0.000 range.py:999(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 selectn.py:44(__init__)\n",
      "        1    0.000    0.000    0.002    0.002 selectn.py:55(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 selectn.py:63(is_valid_dtype_n_method)\n",
      "        1    0.000    0.000    0.001    0.001 selectn.py:90(compute)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:1087(_slice)\n",
      "        8    0.000    0.000    0.000    0.000 series.py:1471(_set_as_cached)\n",
      "        8    0.000    0.000    0.000    0.000 series.py:1480(_clear_item_cache)\n",
      "        2    0.000    0.000    0.004    0.002 series.py:1624(reset_index)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:2083(to_frame)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:2528(duplicated)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:3687(sort_values)\n",
      "        6    0.000    0.000    0.001    0.000 series.py:389(__init__)\n",
      "        1    0.000    0.000    0.002    0.002 series.py:4154(nlargest)\n",
      "        1    0.000    0.000    0.049    0.049 series.py:4789(apply)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:5259(drop)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:5820(dropna)\n",
      "        5    0.000    0.000    0.000    0.000 series.py:660(_constructor)\n",
      "        7    0.000    0.000    0.000    0.000 series.py:664(_constructor_from_mgr)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:687(_constructor_expanddim_from_mgr)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:702(_can_hold_na)\n",
      "       17    0.000    0.000    0.000    0.000 series.py:707(dtype)\n",
      "       18    0.000    0.000    0.000    0.000 series.py:734(name)\n",
      "        8    0.000    0.000    0.000    0.000 series.py:784(name)\n",
      "       21    0.000    0.000    0.000    0.000 series.py:831(_values)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:865(_references)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:872(array)\n",
      "        5    0.000    0.000    0.000    0.000 series.py:914(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:978(__array__)\n",
      "        3    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 shape_base.py:215(_vhstack_dispatcher)\n",
      "        3    0.025    0.008    0.025    0.008 shape_base.py:219(vstack)\n",
      "        3    0.000    0.000    0.000    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 shape_base.py:81(atleast_2d)\n",
      "        1    0.000    0.000    0.000    0.000 sorting.py:122(get_group_index)\n",
      "        1    0.000    0.000    0.000    0.000 sorting.py:157(_int64_cut_off)\n",
      "        1    0.000    0.000    0.000    0.000 sorting.py:170(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 sorting.py:238(is_int64_overflow_possible)\n",
      "        1    0.001    0.001    0.001    0.001 sorting.py:246(_decons_group_index)\n",
      "        1    0.000    0.000    0.001    0.001 sorting.py:268(decons_obs_group_ids)\n",
      "        1    0.000    0.000    0.001    0.001 sorting.py:369(nargsort)\n",
      "        1    0.002    0.002    0.004    0.004 sorting.py:687(compress_group_index)\n",
      "        1    0.000    0.000    0.003    0.003 sorting.py:718(_reorder_by_uniques)\n",
      "        1    0.000    0.000    0.000    0.000 string_.py:140(construct_from_string)\n",
      "       18    0.002    0.000    0.002    0.000 take.py:120(_take_nd_ndarray)\n",
      "       18    0.000    0.000    0.000    0.000 take.py:325(_get_take_nd_function)\n",
      "       18    0.000    0.000    0.000    0.000 take.py:564(_take_preprocess_indexer_and_fill_value)\n",
      "       18    0.000    0.000    0.002    0.000 take.py:59(take_nd)\n",
      "       86    0.000    0.000    0.000    0.000 typing.py:2256(cast)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:187(validate_indices)\n",
      "        5    0.000    0.000    0.000    0.000 utils.py:239(maybe_convert_indices)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:38(is_valid_positional_slice)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:419(check_array_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:62(is_list_like_indexer)\n",
      "        5    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\n",
      "        1    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\n",
      "        6    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "       19    0.000    0.000    0.000    0.000 warnings.py:440(__init__)\n",
      "       19    0.000    0.000    0.000    0.000 warnings.py:466(__enter__)\n",
      "       19    0.000    0.000    0.000    0.000 warnings.py:487(__exit__)\n",
      "       89    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x555555a8b860}\n",
      "       78    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    49772    0.061    0.000    0.061    0.000 {built-in method _codecs.utf_8_decode}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _locale.setlocale}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _operator.inv}\n",
      "       44    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       36    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    6.685    6.685 {built-in method builtins.exec}\n",
      "      562    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       84    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "      101    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "119522/119498    0.015    0.000    0.015    0.000 {built-in method builtins.isinstance}\n",
      "      148    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "118204/118003    0.016    0.000    0.016    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.036    0.036    0.036    0.036 {built-in method io.open}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "       23    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "  150/148    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "      122    0.006    0.000    0.006    0.000 {built-in method numpy.empty}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method numpy.lib.array_utils.normalize_axis_index}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method strptime}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sys.getrefcount}\n",
      "       18    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x7fffbbec7240}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "   117524    0.015    0.000    0.015    0.000 {method 'append' of 'list' objects}\n",
      "       12    0.021    0.002    0.021    0.002 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'as_arrays' of 'numpy._core._multiarray_umath._array_converter' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "       23    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       24    0.003    0.000    0.003    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'date' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234824    0.025    0.000    0.025    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       68    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   117417    0.009    0.000    0.009    0.000 {method 'keys' of 'dict' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "   234825    0.099    0.000    0.099    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "   117409    0.031    0.000    0.031    0.000 {method 'startswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        9    0.001    0.000    0.001    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'weekday' of 'datetime.date' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'wrap' of 'numpy._core._multiarray_umath._array_converter' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q1_benchmark(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `6.685` segundos y se puede ver que más tiempo tomó fue la deserialización de los registros a diccionarios usando el método `loads()`, que tomó un `4.926` segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q1_benchmark.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     6    402.9 MiB    402.9 MiB           1   def q1_benchmark(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
       "     7    402.9 MiB      0.0 MiB           1       records = []\n",
       "     8   1294.7 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "     9   1294.7 MiB     28.6 MiB      117408           for line in jfile:\n",
       "    10   1294.7 MiB    863.1 MiB      117407               records.append(json.loads(line))\n",
       "    11   1295.8 MiB      1.1 MiB           1       df = DataFrame.from_records(records)\n",
       "    12   1303.0 MiB      7.2 MiB           1       df[\"date\"] = df[\"date\"].str[:10]\n",
       "    13   1303.0 MiB      0.0 MiB      234815       df[\"username\"] = df[\"user\"].apply(lambda x: x[\"username\"])\n",
       "    14                                         \n",
       "    15   1303.0 MiB      0.0 MiB           1       df_by_day = df.groupby([\"date\"])[\"date\"].count().nlargest(10).reset_index(name=\"count\")\n",
       "    16   1303.0 MiB      0.0 MiB           1       df_by_day_user = df.groupby([\"date\",\"username\"]).size().sort_values(ascending=False).reset_index(name=\"count\").drop_duplicates(subset=\"date\")\n",
       "    17                                         \n",
       "    18   1303.0 MiB      0.0 MiB           1       df_join = df_by_day.set_index(\"date\").join(df_by_day_user[[\"date\", \"username\"]].set_index(\"date\"), on=\"date\", how=\"left\")\n",
       "    19                                         \n",
       "    20   1303.0 MiB      0.0 MiB           1       results = list(zip(df_join[\"username\"].index, df_join[\"username\"]))\n",
       "    21   1303.0 MiB      0.0 MiB          13       results_cast = [(datetime.strptime(x[0], '%Y-%m-%d').date(), x[1]) for x in results]\n",
       "    22   1303.0 MiB      0.0 MiB           1       return results_cast"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q1_benchmark q1_benchmark(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `1303.9 MiB` de memoria. El punto de mayor incremento es la acumulación de registros en forma de diccionarios en la lista de elementos leídos desde el archivo, generando un incremento de `880.5 MiB`. También es importante notar el uso de recursos al momento de la definición del método: `402.9 MiB` utilizados solo por las dependencias del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q1_memory\n",
    "<a id='q1_memory'></a>\n",
    "\n",
    "`app/src/q1_memory.py`\n",
    "\n",
    "Este método apunta a optimizar el uso de memoria. Para esto, lo primero que se modificó respecto del **benchmark** fue el uso de `pandas`, reemplazándolo por librerías estándar de Python. Otro punto de mejora en términos de uso de memoria fue evitar el uso de diccionarios para almacenar los registros, por lo que se usó una lista de tuplas que solo almacena las partes necesarias de los datos a analizar.\n",
    "\n",
    "**NOTA:** El kernel se reinició en este punto para limpiar cualquier `import` anterior no utilizado en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_memory import q1_memory\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q1_memory(file_path: str)**\n",
    "\n",
    "Toma la ruta del archivo de datos como parámetro. Abre el archivo y lo lee línea por línea y deserializa cada registro como un diccionario y almacena solo los datos necesarios en una lista de tuplas. Se ordena la lista de tuplas por el campo de fecha y se agrupan para obtener la lista de los 10 días con más tweets.\n",
    "\n",
    "Luego se ordena por fecha y username, y se agrupa para obtener los usuarios con mayor cantidad de tweets por día.\n",
    "\n",
    "Finalmente se itera sobre la lista de los 10 días con más tweets y por cada uno se obtiene el usuario con más tweets correspondiente. Los resultado son almacenados en una lista de tuplas que es retornada como resultado.\n",
    "\n",
    "Se agrega una serie de comandos para eliminar las listas generadas y asegurar la liberación de memoria, aunque más adelante, en el perfilado de uso de memoria se evidencia que no aporta sustancialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[datetime.date, str]]`.\n",
    "\n",
    "La lista es igual que la generada por el método `q1_benchmark()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2473223 function calls in 3.665 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.042    0.000    0.098    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.004    0.004    3.665    3.665 <string>:1(<module>)\n",
      "   117407    0.105    0.000    2.348    0.000 __init__.py:299(loads)\n",
      "       10    0.000    0.000    0.000    0.000 _strptime.py:26(_getlang)\n",
      "       10    0.000    0.000    0.001    0.000 _strptime.py:309(_strptime)\n",
      "       10    0.000    0.000    0.001    0.000 _strptime.py:565(_strptime_datetime)\n",
      "   117407    0.161    0.000    2.204    0.000 decoder.py:332(decode)\n",
      "   117407    1.929    0.000    1.929    0.000 decoder.py:343(raw_decode)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:396(normalize)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:479(_parse_localename)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:593(getlocale)\n",
      "   117407    0.012    0.000    0.012    0.000 q1_memory.py:14(<lambda>)\n",
      "   117407    0.014    0.000    0.014    0.000 q1_memory.py:15(<lambda>)\n",
      "        1    0.023    0.023    0.037    0.037 q1_memory.py:15(<listcomp>)\n",
      "       13    0.000    0.000    0.000    0.000 q1_memory.py:16(<lambda>)\n",
      "   117407    0.028    0.000    0.028    0.000 q1_memory.py:18(<lambda>)\n",
      "   117407    0.020    0.000    0.020    0.000 q1_memory.py:19(<lambda>)\n",
      "        1    0.048    0.048    0.072    0.072 q1_memory.py:19(<listcomp>)\n",
      "   516460    0.113    0.000    0.113    0.000 q1_memory.py:23(<lambda>)\n",
      "    44159    0.005    0.000    0.005    0.000 q1_memory.py:24(<lambda>)\n",
      "        1    0.725    0.725    3.661    3.661 q1_memory.py:7(q1_memory)\n",
      "    49772    0.056    0.000    0.056    0.000 {built-in method _codecs.utf_8_decode}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _locale.setlocale}\n",
      "        1    0.000    0.000    3.665    3.665 {built-in method builtins.exec}\n",
      "   117427    0.013    0.000    0.013    0.000 {built-in method builtins.isinstance}\n",
      "   169086    0.018    0.000    0.018    0.000 {built-in method builtins.len}\n",
      "       10    0.076    0.008    0.194    0.019 {built-in method builtins.max}\n",
      "        3    0.121    0.040    0.160    0.053 {built-in method builtins.sorted}\n",
      "        1    0.013    0.013    0.013    0.013 {built-in method io.open}\n",
      "       10    0.000    0.000    0.001    0.000 {built-in method strptime}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "   117417    0.012    0.000    0.012    0.000 {method 'append' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'date' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234824    0.022    0.000    0.022    0.000 {method 'end' of 're.Match' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "   234824    0.078    0.000    0.078    0.000 {method 'match' of 're.Pattern' objects}\n",
      "   117407    0.025    0.000    0.025    0.000 {method 'startswith' of 'str' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'weekday' of 'datetime.date' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q1_memory(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `3.665` segundos. Un `45%` más rápido que el método base `q1_benchmark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q1_memory.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     7    108.5 MiB    108.5 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
       "     8    108.5 MiB      0.0 MiB           1       records = []\n",
       "     9    112.3 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "    10    112.3 MiB      0.2 MiB      117408           for line in jfile:\n",
       "    11    112.3 MiB      3.6 MiB      117407               jline = loads(line)\n",
       "    12    112.3 MiB      0.0 MiB      117407               records.append((jline[\"date\"][:10], jline[\"user\"][\"username\"]))\n",
       "    13                                             \n",
       "    14    112.5 MiB      0.1 MiB      234815       ordered_by_date_records = sorted(records, key=lambda x: x[0])\n",
       "    15    112.5 MiB      0.0 MiB      234830       count_by_date = [(k, len(list(g))) for k, g in (groupby(ordered_by_date_records, lambda x: x[0]))]\n",
       "    16    112.5 MiB      0.0 MiB          27       top_count_by_day = sorted(count_by_date, key=lambda x: x[1], reverse=True)[:10]\n",
       "    17                                         \n",
       "    18    119.6 MiB      4.3 MiB      234815       ordered_by_date_username_records = sorted(records, key=lambda x: (x[0], x[1]))\n",
       "    19    119.7 MiB      0.1 MiB      286463       count_by_date_and_user = [(k, len(list(g))) for k, g in (groupby(ordered_by_date_username_records, lambda x: (x[0],x[1])))]\n",
       "    20                                         \n",
       "    21    119.7 MiB      0.0 MiB           1       results = []\n",
       "    22    119.7 MiB      0.0 MiB          11       for top_date in top_count_by_day:\n",
       "    23    119.7 MiB      0.0 MiB     1032930           filter_group = filter(lambda x: x[0][0] == top_date[0], count_by_date_and_user)\n",
       "    24    119.7 MiB      0.0 MiB       88328           username = max(filter_group, key=lambda x: x[1])[0][1]\n",
       "    25    119.7 MiB      0.0 MiB          10           results.append((datetime.strptime(top_date[0], '%Y-%m-%d').date(), username))\n",
       "    26                                         \n",
       "    27    119.7 MiB      0.0 MiB           1       del ordered_by_date_records\n",
       "    28    119.7 MiB      0.0 MiB           1       del count_by_date\n",
       "    29    119.7 MiB      0.0 MiB           1       del top_count_by_day\n",
       "    30    119.7 MiB      0.0 MiB           1       del ordered_by_date_username_records\n",
       "    31    118.8 MiB     -0.9 MiB           1       del count_by_date_and_user\n",
       "    32    118.8 MiB      0.0 MiB           1       return results"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q1_memory q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `118.8 MiB` de memoria. El punto de mayor incremento es la deserialización de elementos leídos desde el archivo, generando un incremento de `3.6 MiB` y la generación de la lista de registros ordenado por fecha y username, que generó un incremento de `4.3 MiB`. También es importante notar el uso de recursos al momento de la definición del método: `108.5 MiB` utilizados solo por las dependencias del método.\n",
    "\n",
    "El uso total de memoria fue `90,9%` mejor que el método base `q1_benchmark`.\n",
    "\n",
    "En este perfilado se puede ver que los comandos de eliminación de variables `del` solo generan una reducción del uso de memoria respecto de una variable. Para el resto no genera diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q1_time\n",
    "<a id='q1_time'></a>\n",
    "\n",
    "`app/src/q1_time.py`\n",
    "\n",
    "Este método apunta a optimizar el tiempo de ejecución. Para esto, al igual que en `q1_memory` se priorizó el uso de librerías estándar de Python. Otro punto de mejora en términos de uso de tiempo de ejecución fue evitar el uso de deserialización de json, por lo que se usó expresiones regulares para obtener la data necesaria para el análisis.\n",
    "\n",
    "**NOTA:** El kernel se reinició en este punto para limpiar cualquier `import` anterior no utilizado en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_time import q1_time\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q1_time(file_path: str)**\n",
    "\n",
    "Toma la ruta del archivo de datos como parámetro. Abre el archivo, lo lee línea por línea, obtiene la información necesaria de cada registro mediante dos búsquedas con expresiones regulares y almacena solo los datos necesarios en una lista de diccionarios. Se ordena la lista de tuplas por el campo de fecha y se agrupan para obtener la lista de los 10 días con más tweets.\n",
    "\n",
    "Luego se ordena por fecha y username, y se agrupa para obtener los usuarios con mayor cantidad de tweets por día.\n",
    "\n",
    "Finalmente se itera sobre la lista de los 10 días con más tweets y por cada uno se obtiene el usuario con más tweets correspondiente. Los resultado son almacenados en una lista de tuplas que es retornada como resultado.\n",
    "\n",
    "Se agrega una serie de comandos para eliminar las listas generadas y asegurar la liberación de memoria, aunque más adelante, en el perfilado de uso de memoria se evidencia que no aporta sustancialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[datetime.date, str]]`.\n",
    "\n",
    "La lista es igual que la generada por el método `q1_benchmark()` y el método `q1_memory()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2473223 function calls in 2.948 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.032    0.000    0.080    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.016    0.016    2.948    2.948 <string>:1(<module>)\n",
      "   234814    0.098    0.000    1.640    0.000 __init__.py:173(search)\n",
      "   234814    0.097    0.000    0.130    0.000 __init__.py:272(_compile)\n",
      "       10    0.000    0.000    0.000    0.000 _strptime.py:26(_getlang)\n",
      "       10    0.000    0.000    0.001    0.000 _strptime.py:309(_strptime)\n",
      "       10    0.000    0.000    0.001    0.000 _strptime.py:565(_strptime_datetime)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:396(normalize)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:479(_parse_localename)\n",
      "       10    0.000    0.000    0.000    0.000 locale.py:593(getlocale)\n",
      "   117407    0.012    0.000    0.012    0.000 q1_time.py:14(<lambda>)\n",
      "   117407    0.012    0.000    0.012    0.000 q1_time.py:15(<lambda>)\n",
      "        1    0.017    0.017    0.029    0.029 q1_time.py:15(<listcomp>)\n",
      "       13    0.000    0.000    0.000    0.000 q1_time.py:16(<lambda>)\n",
      "   117407    0.031    0.000    0.031    0.000 q1_time.py:18(<lambda>)\n",
      "   117407    0.022    0.000    0.022    0.000 q1_time.py:19(<lambda>)\n",
      "        1    0.047    0.047    0.073    0.073 q1_time.py:19(<listcomp>)\n",
      "   516460    0.108    0.000    0.108    0.000 q1_time.py:23(<lambda>)\n",
      "    44159    0.005    0.000    0.005    0.000 q1_time.py:24(<lambda>)\n",
      "        1    0.701    0.701    2.932    2.932 q1_time.py:6(q1_time)\n",
      "    49772    0.048    0.000    0.048    0.000 {built-in method _codecs.utf_8_decode}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _locale.setlocale}\n",
      "        1    0.000    0.000    2.948    2.948 {built-in method builtins.exec}\n",
      "   234834    0.033    0.000    0.033    0.000 {built-in method builtins.isinstance}\n",
      "    51679    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "       10    0.076    0.008    0.189    0.019 {built-in method builtins.max}\n",
      "        3    0.108    0.036    0.151    0.050 {built-in method builtins.sorted}\n",
      "        1    0.025    0.025    0.025    0.025 {built-in method io.open}\n",
      "       10    0.000    0.000    0.001    0.000 {built-in method strptime}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "   117417    0.011    0.000    0.011    0.000 {method 'append' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'date' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'end' of 're.Match' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "   234814    0.033    0.000    0.033    0.000 {method 'group' of 're.Match' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "   234814    1.412    0.000    1.412    0.000 {method 'search' of 're.Pattern' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'weekday' of 'datetime.date' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q1_time(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `2.948` segundos. Un `56%` más rápido que el método base `q1_benchmark`, y `19%` más rápido que `q1_memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q1_time.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     6    109.2 MiB    109.2 MiB           1   def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
       "     7    109.2 MiB      0.0 MiB           1       records = []\n",
       "     8    129.7 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "     9    129.7 MiB      3.0 MiB      117408           for line in jfile:\n",
       "    10    129.7 MiB      0.0 MiB      117407               parsed_date = re.search('(?<=\\\"date\\\": \\\").+?(?=\\\")', line).group()[:10]\n",
       "    11    129.7 MiB      3.0 MiB      117407               parsed_username = re.search('(?<=\\\"username\\\": \\\").+?(?=\\\")', line).group()\n",
       "    12    129.7 MiB     14.5 MiB      117407               records.append({\"date\": parsed_date, \"username\": parsed_username})\n",
       "    13                                             \n",
       "    14    129.7 MiB      0.0 MiB      234815       ordered_by_date_records = sorted(records, key=lambda x: x[\"date\"])\n",
       "    15    129.7 MiB      0.0 MiB      234830       count_by_date = [(k, len(list(g))) for k, g in (groupby(ordered_by_date_records, lambda x: x[\"date\"]))]\n",
       "    16    129.7 MiB      0.0 MiB          27       top_count_by_day = sorted(count_by_date, key=lambda x: x[1], reverse=True)[:10]\n",
       "    17                                         \n",
       "    18    136.9 MiB      3.1 MiB      234815       ordered_by_date_username_records = sorted(records, key=lambda x: (x[\"date\"], x[\"username\"]))\n",
       "    19    136.8 MiB     -0.1 MiB      286463       count_by_date_and_user = [(k, len(list(g))) for k, g in (groupby(ordered_by_date_username_records, lambda x: (x[\"date\"],x[\"username\"])))]\n",
       "    20                                         \n",
       "    21    136.8 MiB      0.0 MiB           1       results = []\n",
       "    22    136.8 MiB      0.0 MiB          11       for top_date in top_count_by_day:\n",
       "    23    136.8 MiB      0.0 MiB     1032930           filter_group = filter(lambda x: x[0][0] == top_date[0], count_by_date_and_user)\n",
       "    24    136.8 MiB      0.0 MiB       88328           username = max(filter_group, key=lambda x: x[1])[0][1]\n",
       "    25    136.8 MiB      0.0 MiB          10           results.append((datetime.strptime(top_date[0], '%Y-%m-%d').date(), username))\n",
       "    26                                         \n",
       "    27    136.8 MiB      0.0 MiB           1       return results"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q1_time q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `136.8 MiB` de memoria. El punto de mayor incremento es la acumulación de elementos deserializados en la lista de diccionarios, generando un incremento de `14.5 MiB` y la generación de la lista de registros ordenado por fecha y username, que generó un incremento de `3.1 MiB`. También es importante notar el uso de recursos al momento de la definición del método: `109.2 MiB` utilizados solo por las dependencias del método.\n",
    "\n",
    "El uso total de memoria fue `89,5%` mejor que el método base `q1_benchmark`. Pero también un un `15%` **peor** que `q1_memory`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Q1\n",
    "<a id='q1_resultados'></a>\n",
    "\n",
    "|Método | Tiempo de ejecución | Uso de memoria total |\n",
    "|-------|---------------------|----------------------|\n",
    "|q1_benchmark| 6.685 s| 1,303.9 MiB|\n",
    "|q1_memory| 3.665 s| **118.8 MiB**|\n",
    "|q1_time| **2.948 s**| 136.8 MiB|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2 (Q2)\n",
    "<a id='q2_pregunta'></a>\n",
    "\n",
    "Se requiere obtener los 10 emojis más usados. Se considera cada aparición individual para el conteo, es decir, en un único post pueden aparecen múltiples emojis o múltiples apariciones del mismo.\n",
    "\n",
    "**NOTA:** Para este caso no se utilizó un caso de benchmark con herramientas como `pandas` ya que en la pregunta anterior se demostró que no es ideal si se quiere optimizar tiempo de ejecución o uso de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q2_memory\n",
    "<a id='q2_memory'></a>\n",
    "\n",
    "`app/src/q2_memory.py`\n",
    "\n",
    "Este método apunta a optimizar el uso de memoria. Para esto se evita el uso de estructuras de datos innecesarias y también se evita almacenar data que no será usada downstream en el proceso.\n",
    "\n",
    "**NOTA:** El kernel se reinició en este punto para limpiar cualquier `import` anterior no utilizado en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q2_memory import q2_memory\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q2_memory(file_path: str)**\n",
    "\n",
    "Al leer el archivo se deserializa el registro pero solo se almacena la parte necesaria del dato, en este caso el contenido del campo `content`, en el que se buscará el uso de emojis. Luego se obtiene el listado de caracteres considerados \"emojis\" según el diccionario disponible en la librería `emoji`. Luego se recorre caracter por caracter todos los registros obtenidos y se evalúa si son emojis. En caso de ser un emoji, se agregan a un contador que se almacena en un diccionario, donde cada emoji encontrado es una llave y su valor es la cantidad de veces que se ha encontrado. El diccionario resultante con el conteo se transforma en una lista de tuplas, se ordena de mayor a menor y se retorna el top 10 como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 7286),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('✊', 2411),\n",
       " ('🌾', 2363),\n",
       " ('🏻', 2080),\n",
       " ('❤', 1779),\n",
       " ('🤣', 1668),\n",
       " ('🏽', 1218),\n",
       " ('👇', 1108)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[str, int]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1319903 function calls in 4.320 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.036    0.000    0.087    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.005    0.005    4.320    4.320 <string>:1(<module>)\n",
      "   117407    0.102    0.000    2.259    0.000 __init__.py:299(loads)\n",
      "   117407    0.157    0.000    2.120    0.000 decoder.py:332(decode)\n",
      "   117407    1.858    0.000    1.858    0.000 decoder.py:343(raw_decode)\n",
      "      641    0.000    0.000    0.000    0.000 q2_memory.py:16(<lambda>)\n",
      "        1    1.309    1.309    4.315    4.315 q2_memory.py:5(q2_memory)\n",
      "        1    0.638    0.638    2.983    2.983 q2_memory.py:7(<listcomp>)\n",
      "    49772    0.050    0.000    0.050    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    4.320    4.320 {built-in method builtins.exec}\n",
      "   117407    0.012    0.000    0.012    0.000 {built-in method builtins.isinstance}\n",
      "   117407    0.013    0.000    0.013    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.019    0.019    0.019    0.019 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.020    0.000    0.020    0.000 {method 'end' of 're.Match' objects}\n",
      "    45636    0.004    0.000    0.004    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "   234814    0.071    0.000    0.071    0.000 {method 'match' of 're.Pattern' objects}\n",
      "   117407    0.024    0.000    0.024    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q2_memory(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `4.320` segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q2_memory.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     5    135.1 MiB    135.1 MiB           1   def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
       "     6    151.0 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "     7    151.0 MiB     15.9 MiB      117410           records = [json.loads(line)[\"content\"] for line in jfile]\n",
       "     8                                         \n",
       "     9    151.0 MiB      0.0 MiB           1       emoji_list = EMOJI_DATA.keys()\n",
       "    10    151.0 MiB      0.0 MiB           1       emoji_count = {}\n",
       "    11    151.4 MiB      0.0 MiB      117408       for record in records:\n",
       "    12    151.4 MiB      0.4 MiB    17151490           for char in record:\n",
       "    13    151.4 MiB      0.0 MiB    17034083               if char in emoji_list:\n",
       "    14    151.4 MiB      0.0 MiB       45636                   current_count = emoji_count.get(char, 0)\n",
       "    15    151.4 MiB      0.0 MiB       45636                   emoji_count[char] = current_count + 1\n",
       "    16    151.4 MiB      0.0 MiB        1283       emoji_found_sorted = sorted(list(emoji_count.items()), key=lambda x: x[1], reverse=True)\n",
       "    17                                             \n",
       "    18    151.4 MiB      0.0 MiB           1       return emoji_found_sorted[:10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q2_memory q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `151.4 MiB` de memoria. El punto de mayor incremento es la acumulación de elementos deserializados en la lista de diccionarios, generando un incremento de `15.9 MiB`. También es importante notar el uso de recursos al momento de la definición del método: `135.1 MiB` utilizados solo por las dependencias del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q2_time\n",
    "<a id='q2_time'></a>\n",
    "\n",
    "`app/src/q2_time.py`\n",
    "\n",
    "Este método apunta a optimizar el uso de memoria. Para esto se utiliza la posibilidad de procesamiento paralelo que ofrece python a través de la librería estándar `threading`.\n",
    "\n",
    "**NOTA:** El kernel se reinició en este punto para limpiar cualquier `import` anterior no utilizado en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q2_time import q2_time\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q2_time(file_path: str)**\n",
    "\n",
    "Al leer el archivo se deserializa el registro pero solo se almacena la parte necesaria del dato, en este caso el contenido del campo `content`, en el que se buscará el uso de emojis. La lista de registros es dividida en grupos y cada grupo es procesado de forma independiente en un thread. Se utiliza una función auxiliar `count_emojis` que se aplica a cada grupo de registros.\n",
    "\n",
    "En cada grupo se buscan los emojis por caracter y se almacenan en diccionarios donde se lleva el conteo. Cuando todos los threads han terminado de procesar se juntan los diccionarios de resultados en un `Counter` que sumará los resultados independientes.\n",
    "\n",
    "Finalmente se transforma el counter en una lista de tuplas, se ordena y luego se toma el 10 y se retorna como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 7286),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('✊', 2411),\n",
       " ('🌾', 2363),\n",
       " ('🏻', 2080),\n",
       " ('❤', 1779),\n",
       " ('🤣', 1668),\n",
       " ('🏽', 1218),\n",
       " ('👇', 1108)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[str, int]]`. Es igual al resultado generado por la función `q2_memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1394992 function calls in 3.674 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen abc>:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.037    0.000    0.087    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.005    0.005    3.674    3.674 <string>:1(<module>)\n",
      "   117407    0.101    0.000    2.251    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:587(__init__)\n",
      "       13    0.001    0.000    0.001    0.000 __init__.py:660(update)\n",
      "       12    0.000    0.000    0.000    0.000 _weakrefset.py:39(_remove)\n",
      "       12    0.000    0.000    0.000    0.000 _weakrefset.py:85(add)\n",
      "   117407    0.153    0.000    2.114    0.000 decoder.py:332(decode)\n",
      "   117407    1.855    0.000    1.855    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.763    0.763    3.668    3.668 q2_time.py:18(q2_time)\n",
      "      641    0.000    0.000    0.000    0.000 q2_time.py:42(<lambda>)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:1051(_stop)\n",
      "       12    0.000    0.000    0.134    0.011 threading.py:1087(join)\n",
      "       12    0.000    0.000    0.134    0.011 threading.py:1125(_wait_for_tstate_lock)\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:1206(daemon)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:1324(_make_invoke_excepthook)\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:1453(current_thread)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:243(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:271(__enter__)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:274(__exit__)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:280(_release_save)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:283(_acquire_restore)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:286(_is_owned)\n",
      "       12    0.000    0.000    0.382    0.032 threading.py:295(wait)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:562(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:575(is_set)\n",
      "       12    0.000    0.000    0.382    0.032 threading.py:611(wait)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:811(_newname)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:829(_maintain_shutdown_locks)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:839(<listcomp>)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:856(__init__)\n",
      "       12    0.000    0.000    0.383    0.032 threading.py:945(start)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    49772    0.050    0.000    0.050    0.000 {built-in method _codecs.utf_8_decode}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       12    0.001    0.000    0.001    0.000 {built-in method _thread.start_new_thread}\n",
      "        1    0.000    0.000    3.674    3.674 {built-in method builtins.exec}\n",
      "   117419    0.012    0.000    0.012    0.000 {built-in method builtins.isinstance}\n",
      "   117408    0.013    0.000    0.013    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.033    0.033    0.033    0.033 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {function Counter.update at 0x7ffffef909a0}\n",
      "       12    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       60    0.516    0.009    0.516    0.009 {method 'acquire' of '_thread.lock' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "   117419    0.015    0.000    0.015    0.000 {method 'append' of 'list' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'difference_update' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "   234814    0.020    0.000    0.020    0.000 {method 'end' of 're.Match' objects}\n",
      "     2619    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       73    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "   234814    0.074    0.000    0.074    0.000 {method 'match' of 're.Pattern' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "   117407    0.024    0.000    0.024    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q2_time(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `3.674` segundos. Un `15%` más rápido que `q2_memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q2_time.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "    18    128.5 MiB    128.5 MiB           1   def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
       "    19    128.5 MiB      0.0 MiB           1       records = []\n",
       "    20    139.2 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "    21    139.2 MiB      0.0 MiB      117408           for line in jfile:\n",
       "    22    139.2 MiB     10.6 MiB      117407               jline = json.loads(line)\n",
       "    23    139.2 MiB      0.0 MiB      117407               records.append(jline[\"content\"])\n",
       "    24                                         \n",
       "    25    139.7 MiB      0.5 MiB           1       emoji_list = set(EMOJI_DATA.keys())\n",
       "    26    139.7 MiB      0.0 MiB           1       threads = []\n",
       "    27    139.7 MiB      0.0 MiB           1       results = []\n",
       "    28                                         \n",
       "    29    139.7 MiB      0.0 MiB           1       chunk_size = 10000\n",
       "    30    139.8 MiB     -0.1 MiB          13       for i in range((len(records)//chunk_size)+1):\n",
       "    31    139.8 MiB     -0.1 MiB          12           task = Thread(target=count_emojis, kwargs={\"record_list\":records[i*chunk_size:(i+1)*chunk_size], \"emoji_list\": emoji_list, \"results\":results})\n",
       "    32    139.8 MiB     -0.1 MiB          12           threads.append(task)\n",
       "    33    139.8 MiB      0.0 MiB          12           task.start()\n",
       "    34                                             \n",
       "    35    139.8 MiB      0.0 MiB          13       for task in threads:\n",
       "    36    139.8 MiB      0.0 MiB          12               task.join()\n",
       "    37                                         \n",
       "    38    139.8 MiB      0.0 MiB           1       c = Counter()\n",
       "    39    139.8 MiB      0.0 MiB          13       for count in results:\n",
       "    40    139.8 MiB      0.0 MiB          12           c.update(count)\n",
       "    41                                             \n",
       "    42    139.8 MiB      0.0 MiB        1283       return sorted(list(dict(c).items()), key=lambda x: x[1], reverse=True)[:10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q2_time q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `139.8 MiB` de memoria. Ocupa un `7%` menos de memoria que el caso anterior. A pesar de que la lectura del archivo es la misma y rescata la misma cantidad de data que `q2_memory`, parece tener un incremento menor de consumo.\n",
    "\n",
    "Curiosamente, a pesar de enfocar el esfuerzo de esta solución a la velocidad de ejecución mediante paralelización, esto parece tener también un beneficio en la liberación de recursos del proceso.\n",
    "\n",
    "También es importante notar el uso de recursos al momento de la definición del método: `128.5 MiB` utilizados solo por las dependencias del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Q2\n",
    "<a id='q2_resultados'></a>\n",
    "\n",
    "|Método | Tiempo de ejecución | Uso de memoria total |\n",
    "|-------|---------------------|----------------------|\n",
    "|q2_memory| 4.320 s| 151.4 MiB|\n",
    "|q2_time| **3.674 s**| **139.8 MiB**|\n",
    "\n",
    "`q2_time` resultó mejor en ambos aspectos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 3 (Q2)\n",
    "<a id='q3_pregunta'></a>\n",
    "\n",
    "Se requiere obtener la lista de los 10 usernames más mencionados. Se considera cada aparición individual para el conteo, es decir, en un único post pueden aparecen múltiples menciones de distintos o el mismo username.\n",
    "\n",
    "**NOTA:** Para este caso tampoco se utilizó un caso de benchmark con herramientas como `pandas` ya que en la pregunta anterior se demostró que no es ideal si se quiere optimizar tiempo de ejecución o uso de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q3_memory\n",
    "<a id='q3_memory'></a>\n",
    "\n",
    "`app/src/q3_memory.py`\n",
    "\n",
    "Este método apunta a optimizar el uso de memoria. Para esto se evita el uso de estructuras de datos innecesarias y también se evita almacenar data que no será usada downstream en el proceso usando un filtro adicional.\n",
    "\n",
    "**NOTA:** El kernel se reinició en este punto para limpiar cualquier `import` anterior no utilizado en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q3_memory import q3_memory\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q3_memory(file_path: str)**\n",
    "\n",
    "Al leer el archivo se deserializa el registro pero solo se almacena la parte necesaria del dato, en este caso el contenido del campo `content`, en el que se buscarán las menciones de usernames. Además, al rescatar los datos se almacenan solo aquellos registros que tengan al menos un `@` en su contenido, esto para evitar almacenar aquellos registros que se puede asegurar que no tienen ninguna mención.\n",
    "\n",
    "Sobre la lista de registros que contienen al menos un `@` se aplica una expresión regular que lista todas las menciones de usernames válidos. Se itera sobre la lista de usernames válidos y se lleva el conteo de estos en un diccionario.\n",
    "\n",
    "Cuando se termina de iterar sobre todos los registros y sobre todas las menciones, el diccionario de conteo se transforma en una lista de tuplas, se ordena y se retorna el top 10 como resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@narendramodi', 2261),\n",
       " ('@Kisanektamorcha', 1836),\n",
       " ('@RakeshTikaitBKU', 1639),\n",
       " ('@PMOIndia', 1422),\n",
       " ('@RahulGandhi', 1125),\n",
       " ('@GretaThunberg', 1046),\n",
       " ('@RaviSinghKA', 1015),\n",
       " ('@rihanna', 972),\n",
       " ('@UNHumanRights', 962),\n",
       " ('@meenaharris', 925)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[str, int]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1144593 function calls in 2.262 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.043    0.000    0.097    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.002    0.002    2.262    2.262 <string>:1(<module>)\n",
      "    55172    0.024    0.000    0.068    0.000 __init__.py:218(finditer)\n",
      "    55172    0.022    0.000    0.030    0.000 __init__.py:272(_compile)\n",
      "    55172    0.056    0.000    1.221    0.000 __init__.py:299(loads)\n",
      "    55172    0.077    0.000    1.146    0.000 decoder.py:332(decode)\n",
      "    55172    1.014    0.000    1.014    0.000 decoder.py:343(raw_decode)\n",
      "    55172    0.084    0.000    0.097    0.000 q3_memory.py:11(<listcomp>)\n",
      "    15514    0.002    0.000    0.002    0.000 q3_memory.py:16(<lambda>)\n",
      "        1    0.064    0.064    2.260    2.260 q3_memory.py:5(q3_memory)\n",
      "        1    0.657    0.657    1.974    1.974 q3_memory.py:7(<listcomp>)\n",
      "    49772    0.054    0.000    0.054    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    2.262    2.262 {built-in method builtins.exec}\n",
      "   110344    0.014    0.000    0.014    0.000 {built-in method builtins.isinstance}\n",
      "    55172    0.007    0.000    0.007    0.000 {built-in method builtins.len}\n",
      "        1    0.003    0.003    0.004    0.004 {built-in method builtins.sorted}\n",
      "        1    0.037    0.037    0.037    0.037 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   110344    0.010    0.000    0.010    0.000 {method 'end' of 're.Match' objects}\n",
      "    55172    0.013    0.000    0.013    0.000 {method 'finditer' of 're.Pattern' objects}\n",
      "   100972    0.015    0.000    0.015    0.000 {method 'get' of 'dict' objects}\n",
      "   100972    0.013    0.000    0.013    0.000 {method 'group' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   110344    0.039    0.000    0.039    0.000 {method 'match' of 're.Pattern' objects}\n",
      "    55172    0.012    0.000    0.012    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q3_memory(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `2.262` segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q3_memory.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     5    104.1 MiB    104.1 MiB           1   def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
       "     6    109.2 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "     7    109.2 MiB      5.1 MiB      117410           records = [json.loads(line)[\"content\"] for line in jfile if '@' in line]\n",
       "     8                                         \n",
       "     9    109.2 MiB      0.0 MiB           1       mention_counter = {}\n",
       "    10    113.3 MiB      0.0 MiB       55173       for record in records:\n",
       "    11    113.3 MiB      2.5 MiB      266488           mentions = [mention.group() for mention in re.finditer(r\"@([a-zA-Z0-9_]){4,15}\\b\", record)]\n",
       "    12    113.3 MiB      0.0 MiB      156144           for mention in mentions:\n",
       "    13    113.3 MiB      0.0 MiB      100972               current_count = mention_counter.get(mention, 0)\n",
       "    14    113.3 MiB      1.6 MiB      100972               mention_counter[mention] = current_count + 1\n",
       "    15                                         \n",
       "    16    114.2 MiB      0.9 MiB       31029       mention_counter_sorted = sorted(list(mention_counter.items()), key=lambda x: x[1], reverse=True)\n",
       "    17                                             \n",
       "    18    114.2 MiB      0.0 MiB           1       return mention_counter_sorted[:10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q3_memory q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `114.2 MiB` de memoria. El mayor incremento se debe al almacenamiento de registros que contienen un `@`, lo que genera un incremento de uso de memoria de `5.1 MiB`. También es importante notar el uso de recursos al momento de la definición del método: `104.1 MiB` utilizados solo por las dependencias del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q3_time\n",
    "<a id='q3_time'></a>\n",
    "\n",
    "`app/src/q3_time.py`\n",
    "\n",
    "Este método apunta a optimizar el uso de memoria. Para esto se utiliza la posibilidad de procesamiento paralelo que ofrece python a través de la librería estándar `threading`.\n",
    "\n",
    "**NOTA:** El kernel se reinició en este punto para limpiar cualquier `import` anterior no utilizado en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q3_time import q3_time\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: q3_time(file_path: str)**\n",
    "\n",
    "Este método sigue la misma estructura que en el caso `q2_time`, salvo por el uso de un filtro al momento de leer los registros del archivo, asegurando que tengan al menos una vez el caracter `@`. Al leer el archivo se deserializa el registro pero solo se almacena la parte necesaria del dato, en este caso el contenido del campo `content`, en el que se buscarán las menciones de usernames. La lista de registros es dividida en grupos y cada grupo es procesado de forma independiente en un thread. Se utiliza una función auxiliar `count_mentions` que se aplica a cada grupo de registros.\n",
    "\n",
    "En cada grupo se buscan las menciones mediante expresiones regulares y se almacenan en diccionarios donde se lleva el conteo. Cuando todos los threads han terminado de procesar se juntan los diccionarios de resultados en un `Counter` que sumará los resultados independientes.\n",
    "\n",
    "Finalmente se transforma el counter en una lista de tuplas, se ordena y luego se toma el 10 y se retorna como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@narendramodi', 2261),\n",
       " ('@Kisanektamorcha', 1836),\n",
       " ('@RakeshTikaitBKU', 1639),\n",
       " ('@PMOIndia', 1422),\n",
       " ('@RahulGandhi', 1125),\n",
       " ('@GretaThunberg', 1046),\n",
       " ('@RaviSinghKA', 1015),\n",
       " ('@rihanna', 972),\n",
       " ('@UNHumanRights', 962),\n",
       " ('@meenaharris', 925)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecución directa\n",
    "q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una lista de 10 elementos con el formato y tipo esperado `List[Tuple[str, int]]`. Es igual al resultado generado por la función `q3_memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         687777 function calls in 2.118 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen abc>:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "    49772    0.034    0.000    0.084    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.002    0.002    2.118    2.118 <string>:1(<module>)\n",
      "    55172    0.050    0.000    1.214    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:587(__init__)\n",
      "        7    0.006    0.001    0.008    0.001 __init__.py:660(update)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:39(_remove)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:85(add)\n",
      "    55172    0.073    0.000    1.146    0.000 decoder.py:332(decode)\n",
      "    55172    1.021    0.000    1.021    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.003    0.003    2.116    2.116 q3_time.py:18(q3_time)\n",
      "        1    0.663    0.663    1.960    1.960 q3_time.py:21(<listcomp>)\n",
      "    15514    0.002    0.000    0.002    0.000 q3_time.py:39(<lambda>)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:1051(_stop)\n",
      "        6    0.000    0.000    0.004    0.001 threading.py:1087(join)\n",
      "        6    0.000    0.000    0.004    0.001 threading.py:1125(_wait_for_tstate_lock)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:1206(daemon)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:1324(_make_invoke_excepthook)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:1453(current_thread)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:243(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:271(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:274(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:280(_release_save)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:283(_acquire_restore)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:286(_is_owned)\n",
      "        6    0.000    0.000    0.107    0.018 threading.py:295(wait)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:562(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:575(is_set)\n",
      "        6    0.000    0.000    0.107    0.018 threading.py:611(wait)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:811(_newname)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:829(_maintain_shutdown_locks)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:839(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:856(__init__)\n",
      "        6    0.000    0.000    0.108    0.018 threading.py:945(start)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    49772    0.049    0.000    0.049    0.000 {built-in method _codecs.utf_8_decode}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "        1    0.000    0.000    2.118    2.118 {built-in method builtins.exec}\n",
      "    55178    0.006    0.000    0.006    0.000 {built-in method builtins.isinstance}\n",
      "    55173    0.006    0.000    0.006    0.000 {built-in method builtins.len}\n",
      "        1    0.003    0.003    0.004    0.004 {built-in method builtins.sorted}\n",
      "        1    0.028    0.028    0.028    0.028 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {function Counter.update at 0x7ffffef909a0}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       30    0.111    0.004    0.111    0.004 {method 'acquire' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'difference_update' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "   110344    0.010    0.000    0.010    0.000 {method 'end' of 're.Match' objects}\n",
      "    20654    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "   110344    0.036    0.000    0.036    0.000 {method 'match' of 're.Pattern' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "    55172    0.012    0.000    0.012    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfilado de tiempo de ejecución\n",
    "import cProfile\n",
    "cProfile.run('q3_time(file_path)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución tomó un total de `2.118` segundos. Un `6%` más rápido que `q3_memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /app/src/q3_time.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "    18    107.4 MiB    107.4 MiB           1   def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
       "    19    107.4 MiB      0.0 MiB           1       records = []\n",
       "    20    111.4 MiB      0.0 MiB           2       with open(f\"/app/data/{file_path}\") as jfile:\n",
       "    21    111.4 MiB      4.0 MiB      117410           records = [json.loads(line)[\"content\"] for line in jfile if '@' in line]\n",
       "    22                                         \n",
       "    23    111.4 MiB      0.0 MiB           1       threads = []\n",
       "    24    111.4 MiB      0.0 MiB           1       results = []\n",
       "    25                                         \n",
       "    26    111.4 MiB      0.0 MiB           1       chunk_size = 10000\n",
       "    27    112.7 MiB      0.0 MiB           7       for i in range((len(records)//chunk_size)+1):\n",
       "    28    112.3 MiB      0.0 MiB           6           task = Thread(target=count_mentions, kwargs={\"record_list\":records[i*chunk_size:(i+1)*chunk_size], \"results\":results})\n",
       "    29    112.3 MiB      0.1 MiB           6           threads.append(task)\n",
       "    30    112.7 MiB      1.1 MiB           6           task.start()\n",
       "    31                                             \n",
       "    32    112.8 MiB      0.1 MiB           7       for task in threads:\n",
       "    33    112.8 MiB      0.0 MiB           6               task.join()\n",
       "    34                                         \n",
       "    35    112.8 MiB      0.0 MiB           1       c = Counter()\n",
       "    36    113.2 MiB      0.0 MiB           7       for count in results:\n",
       "    37    113.2 MiB      0.4 MiB           6           c.update(count)\n",
       "    38                                             \n",
       "    39    114.5 MiB      1.4 MiB       31029       return sorted(list(dict(c).items()), key=lambda x: x[1], reverse=True)[:10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perfilado de uso de memoria\n",
    "%load_ext memory_profiler\n",
    "%mprun -f q3_time q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta solución utilizó un total de `114.5 MiB` de memoria. Aproximadamente `0.2%` más que `q3_memory`. También es importante notar el uso de recursos al momento de la definición del método: `107.4 MiB` utilizados solo por las dependencias del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Q3\n",
    "<a id='q3_resultados'></a>\n",
    "\n",
    "|Método | Tiempo de ejecución | Uso de memoria total |\n",
    "|-------|---------------------|----------------------|\n",
    "|q3_memory| 2.262 s| **114.2 MiB**|\n",
    "|q3_time| **2.118 s**| 114.5 MiB|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoras posibles\n",
    "<a id='mejoras_posibles'></a>\n",
    "- **Manejo de errores:** Se puede agregar control de errores con `try - catch` para asegurar que comportamientos no deseados rompan el flujo de estos métodos. El punto más evidente donde se puede implementar esto es en la deserialización de los registros desde el archivo. Para este ejemplo los datos estaban limpios y con buen formato, pero en un caso real es probable recibir registros malformados o incompletos. Aquellos que levanten una `exception` al momento de aplicar `json.loads` se podrían declarar en un log y saltarlos.\n",
    "- **Comentarios:** Dado que se prefirió usar librerías estándar para procesar los datos, además de generadores y funciones `lambda` el código se vuelve más compacto y eficiente, pero también puede ser más difícil de leer, sobretodo para alguien con poca experiencia. Se podrían agregar documentación a través de `docstrings`.\n",
    "- **Modularidad y Clean Architecture:** Dado que el código para cada caso resultó muy compacto, se decidió no utilizar módulos ni un método de desarrollo que separe la lógica en más archivos. Se prefirió reducir al mínimo la abstracción, pero en un caso real, usar métodos de desarrollo modular puede ayudar con la escalabilidad del proyecto, ya sea usando TDD, DDD o Clean Architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Ejecución en la nube?\n",
    "<a id='cloud'></a>\n",
    "Ya que todos los métodos propuestos usan muy poca memoria (`<200 MiB`), podrían ser implementados sin problemas en soluciones serverless como `Cloud Function` de GCP o `Lambda` de AWS. Siempre y cuando se modifique la forma de leer el archivo para que lo saque de algún espacio de almacenamiento en la nube, como `GCS` o `S3`.\n",
    "\n",
    "También se podrían usar otras herramientas para procesar los datos, como `Apache Spark` en `Dataproc` para realizar el procesamiento de forma distribuída, sin embargo, para volúmenes tan pequeños como el caso de ejemplo, sería una forma de `overkill` y probablemente termine demorando más y costando más dinero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
